{"cells":[{"cell_type":"markdown","metadata":{"id":"8cPquP_vmGCY"},"source":["## ‚öôÔ∏èPrerequisites\n","### Setup SSCMA\n","Clone the [repository](https://github.com/Seeed-Studio/ModelAssistant) and install the dependencies."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9GG_RwD7mGCY"},"outputs":[],"source":["!rm -rf ModelAssistant\n","%env PYTHON_EXEC=python3.8\n","!git clone https://review.mlplatform.org/ml/ethos-u/ethos-u-vela.git\n","%cd ethos-u-vela\n","!pip install .\n","%cd ..\n","!git clone https://github.com/Seeed-Studio/ModelAssistant.git   #clone the repo\n","\n","%cd ModelAssistant\n","!git status\n","!. ./scripts/setup_colab.sh"]},{"cell_type":"markdown","metadata":{"id":"OhrHEHBRmGCZ"},"source":["### Download the pretrain model weights file"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ydcrMPJ3mGCZ"},"outputs":[],"source":["%rm -rf pilboi-yolo/\n","%mkdir -p pilboi-yolo\n","!wget -c https://files.seeedstudio.com/sscma/model_zoo/detection/coco/swift_yolo_shuffle_coco_320_float32_sha1_a5927bd6a6c6569d27edb98da946a8e75a8d816f.pth -O pilboi-yolo/pretrain.pth"]},{"cell_type":"markdown","metadata":{"id":"8qCYdNb-mGCZ"},"source":["### Download the dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ho7hsz1CmGCa"},"outputs":[],"source":["\n","%mkdir -p pilboi-yolo/dataset\n","!wget -c https://app.roboflow.com/ -O pilboi-yolo/dataset.zip\n","!unzip -q pilboi-yolo/dataset.zip -d pilboi-yolo/dataset"]},{"cell_type":"markdown","metadata":{"id":"LpERLD7OmGCa"},"source":["## üöÄTrain a model with SSCMA\n","All the training parameters are in the `config.py` file, you can change the parameters to train your own model.\n","\n","Below are explanations of some common parameters. You can also refer to the [documentation](https://sensecraftma.seeed.cc/tutorials/config) for more details.\n","- `data_root` - the datasets path.\n","- `epochs`- the train epochs. **we use 10 epochs as an example**.\n","- `batch_size` - the batch size.\n","- `height` - the image height.\n","- `width` - the image width.\n","- `load_from` - the pretrained model path.\n","- `num_classes` - the number of classes.\n","\n","You can overwrite the parameters in the `config.py` file by using the `--cfg-options` argument.\n","```bash\n","# Example\n","sscma.train config.py --cfg-options data_root=./datasets/test_dataset epochs=10\n","```"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-vEdJZxlmGCa"},"outputs":[],"source":["!pwd\n","!cd /content/ModelAssistant/\n","!ls pilboi-yolo/dataset/valid\n","!sscma.train configs/swift_yolo/swift_yolo_shuff_1xb16_300e_coco.py \\\n","--cfg-options  \\\n","    work_dir=pilboi-yolo \\\n","    num_classes=8 \\\n","    epochs=100  \\\n","    height=256 \\\n","    width=256 \\\n","    data_root=pilboi-yolo/dataset/ \\\n","    load_from=pilboi-yolo/pretrain.pth"]},{"cell_type":"markdown","metadata":{"id":"4sOqGD5GmGCb"},"source":["## üì¶Export the model\n","After training, you can export the model to the format for deployment. SSCMA supports exporting to ONNX, and TensorFlow Lite at present.\n","You can also refer to the [documentation](https://sensecraftma.seeed.cc/tutorials/export/overview) for more details.\n","\n","```bash\n","python3 tools/export.py \\\n","    \"<CONFIG_FILE_PATH>\" \\\n","    \"<CHECKPOINT_FILE_PATH>\"\n","```"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nvgrct8HmGCb"},"outputs":[],"source":["import os\n","with open('pilboi-yolo/last_checkpoint', 'r') as f:\n","\tos.environ['CHECKPOINT_FILE_PATH'] = f.read()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8KPwdfnYmGCb"},"outputs":[],"source":["!sscma.export configs/swift_yolo/swift_yolo_shuff_1xb16_300e_coco.py $CHECKPOINT_FILE_PATH --cfg-options  \\\n","    work_dir=pilboi-yolo \\\n","    num_classes=8 \\\n","    epochs=100  \\\n","    height=256 \\\n","    width=256 \\\n","    data_root=pilboi-yolo/dataset/ \\\n","    load_from=pilboi-yolo/pretrain.pth"]},{"cell_type":"markdown","metadata":{"id":"0dYQOPsDmGCb"},"source":["### üìùEvaluate the model\n","After exporting the model, you can evaluate the model on the test dataset.\n","You can also refer to the [documentation](https://sensecraftma.seeed.cc/tutorials/export/overview) for more details.\n","\n","\n","```bash\n","python3 tools/inference.py \\\n","    \"<CONFIG_FILE_PATH>\" \\\n","    \"<CHECKPOINT_FILE_PATH>\"\n","```"]},{"cell_type":"markdown","metadata":{"id":"jfRoNUEwmGCb"},"source":["### Evaluate the PyTorch model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dEUyzTlsmGCb"},"outputs":[],"source":["!sscma.inference configs/swift_yolo/swift_yolo_shuff_1xb16_300e_coco.py ${CHECKPOINT_FILE_PATH%.*}.pth \\\n","--cfg-options  \\\n","    work_dir=pilboi-yolo \\\n","    num_classes=8 \\\n","    epochs=70  \\\n","    height=256 \\\n","    width=256 \\\n","    data_root=pilboi-yolo/dataset/ \\\n","    load_from=pilboi-yolo/pretrain.pth"]},{"cell_type":"markdown","metadata":{"id":"5FwZecgPmGCc"},"source":["### Evaluate the ONNX model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HsFok8qumGCc"},"outputs":[],"source":["!sscma.inference configs/yolov5/swift_yolo_shuff_1xb16_300e_coco.py ${CHECKPOINT_FILE_PATH%.*}_float32.onnx \\\n","--cfg-options  \\\n","    work_dir=COCO_Detection_Swift-YOLO_320 \\\n","    num_classes=1 \\\n","    epochs=10  \\\n","    height=320 \\\n","    width=320 \\\n","    data_root=COCO_Detection_Swift-YOLO_320/dataset/ \\\n","    load_from=COCO_Detection_Swift-YOLO_320/pretrain.pth"]},{"cell_type":"markdown","metadata":{"id":"c2u9tlfqmGCc"},"source":["### Evaluate the TFLite FLOAT32 model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h5cswC0SmGCc"},"outputs":[],"source":["!sscma.inference configs/yolov5/swift_yolo_shuff_1xb16_300e_coco.py ${CHECKPOINT_FILE_PATH%.*}_float32.tflite \\\n","--cfg-options  \\\n","    work_dir=COCO_Detection_Swift-YOLO_320 \\\n","    num_classes=1 \\\n","    epochs=10  \\\n","    height=320 \\\n","    width=320 \\\n","    data_root=COCO_Detection_Swift-YOLO_320/dataset/ \\\n","    load_from=COCO_Detection_Swift-YOLO_320/pretrain.pth"]},{"cell_type":"markdown","metadata":{"id":"FjZvvWDlmGCc"},"source":["### Evaluate the TFLite INT8 model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x-nHceqemGCc"},"outputs":[],"source":["!sscma.inference configs/swift_yolo/swift_yolo_shuff_1xb16_300e_coco.py ${CHECKPOINT_FILE_PATH%.*}_int8.tflite \\\n","--cfg-options  \\\n","    work_dir=pilboi-yolo \\\n","    num_classes=8 \\\n","    epochs=100  \\\n","    height=256 \\\n","    width=256 \\\n","    data_root=pilboi-yolo/dataset/ \\\n","    load_from=pilboi-yolo/pretrain.pth"]},{"cell_type":"markdown","metadata":{"id":"yy3ra2lxmGCc"},"source":["## ü§ñ Deploy the model\n","After model training, evaluation and export, you can deploy the model to your device. You can refer to [Documentation](https://sensecraftma.seeed.cc/deploy/overview) for more details."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"elapsed":182,"status":"ok","timestamp":1724770773622,"user":{"displayName":"Bryan Staley","userId":"11267470436463418056"},"user_tz":360},"id":"HgmsK7UFtKHF","outputId":"6414216d-3e1c-4e1b-9783-fc099e2f782a"},"outputs":[{"data":{"application/javascript":"\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/javascript":"download(\"download_eea4ce00-9676-424c-b382-78ba23026abc\", \"epoch_100_int8_vela.tflite\", 698480)","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"}],"source":["from google.colab import files\n","files.download(f'pilboi-yolo/epoch_100_int8_vela.tflite')"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"https://github.com/seeed-studio/sscma-model-zoo/blob/main/notebooks/en/COCO_Detection_Swift-YOLO_320.ipynb","timestamp":1720882591560}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.17"}},"nbformat":4,"nbformat_minor":0}
